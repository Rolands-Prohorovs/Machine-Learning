{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5dbbf66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rolan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.7221 - loss: 0.6502 - val_accuracy: 0.8313 - val_loss: 0.4549\n",
      "Epoch 2/5\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.8330 - loss: 0.4179 - val_accuracy: 0.8527 - val_loss: 0.4019\n",
      "Epoch 3/5\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.8665 - loss: 0.3458 - val_accuracy: 0.8873 - val_loss: 0.3189\n",
      "Epoch 4/5\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.8859 - loss: 0.2900 - val_accuracy: 0.8933 - val_loss: 0.2898\n",
      "Epoch 5/5\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.9019 - loss: 0.2573 - val_accuracy: 0.8720 - val_loss: 0.3411\n",
      "Test accuracy (tiny CNN): 0.8569999933242798\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Data\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Keep classes 0,1,2 only\n",
    "mask_train = (y_train < 3).flatten()\n",
    "mask_test = (y_test < 3).flatten()\n",
    "x_train = x_train[mask_train].astype(\"float32\")/255.0\n",
    "y_train = y_train[mask_train].flatten()\n",
    "x_test = x_test[mask_test].astype(\"float32\")/255.0\n",
    "y_test = y_test[mask_test].flatten()\n",
    "\n",
    "# Small CNN model\n",
    "model = models.Sequential([\n",
    "layers.Conv2D(32, (3,3), activation=\"relu\", padding=\"same\", input_shape=(32,32,3)),\n",
    "layers.MaxPooling2D(),\n",
    "layers.Conv2D(64, (3,3), activation=\"relu\", padding=\"same\"),\n",
    "layers.MaxPooling2D(),\n",
    "layers.Conv2D(128, (3,3), activation=\"relu\", padding=\"same\"),\n",
    "layers.MaxPooling2D(),\n",
    "layers.Flatten(),\n",
    "layers.Dense(64, activation=\"relu\"),\n",
    "layers.Dense(3, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "optimizer=\"adam\",\n",
    "loss=\"sparse_categorical_crossentropy\",\n",
    "metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Train\n",
    "history = model.fit(\n",
    "x_train, y_train,\n",
    "epochs=5,\n",
    "batch_size=64,\n",
    "validation_split=0.1,\n",
    "verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "loss, acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Test accuracy (tiny CNN):\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34984983",
   "metadata": {},
   "source": [
    "BatchNorm + Dropout + EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eed85231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 131ms/step - accuracy: 0.7138 - loss: 0.7287 - val_accuracy: 0.3533 - val_loss: 2.9864\n",
      "Epoch 2/30\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 131ms/step - accuracy: 0.8089 - loss: 0.4867 - val_accuracy: 0.4953 - val_loss: 1.6038\n",
      "Epoch 3/30\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 126ms/step - accuracy: 0.8394 - loss: 0.4142 - val_accuracy: 0.7980 - val_loss: 0.4941\n",
      "Epoch 4/30\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 125ms/step - accuracy: 0.8575 - loss: 0.3664 - val_accuracy: 0.7733 - val_loss: 0.5582\n",
      "Epoch 5/30\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 145ms/step - accuracy: 0.8841 - loss: 0.3202 - val_accuracy: 0.8867 - val_loss: 0.2959\n",
      "Epoch 6/30\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 137ms/step - accuracy: 0.8908 - loss: 0.2911 - val_accuracy: 0.8687 - val_loss: 0.3382\n",
      "Epoch 7/30\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 136ms/step - accuracy: 0.8986 - loss: 0.2659 - val_accuracy: 0.9040 - val_loss: 0.2630\n",
      "Epoch 8/30\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 127ms/step - accuracy: 0.9053 - loss: 0.2475 - val_accuracy: 0.8360 - val_loss: 0.5819\n",
      "Epoch 9/30\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 127ms/step - accuracy: 0.9063 - loss: 0.2457 - val_accuracy: 0.9060 - val_loss: 0.2698\n",
      "Epoch 10/30\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 126ms/step - accuracy: 0.9158 - loss: 0.2215 - val_accuracy: 0.9133 - val_loss: 0.2397\n",
      "Epoch 11/30\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 123ms/step - accuracy: 0.9193 - loss: 0.2127 - val_accuracy: 0.8680 - val_loss: 0.3234\n",
      "Epoch 12/30\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 124ms/step - accuracy: 0.9236 - loss: 0.1995 - val_accuracy: 0.9120 - val_loss: 0.2505\n",
      "Epoch 13/30\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 130ms/step - accuracy: 0.9292 - loss: 0.1934 - val_accuracy: 0.9140 - val_loss: 0.2339\n",
      "Epoch 14/30\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 130ms/step - accuracy: 0.9316 - loss: 0.1815 - val_accuracy: 0.9173 - val_loss: 0.2481\n",
      "Epoch 15/30\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 125ms/step - accuracy: 0.9379 - loss: 0.1643 - val_accuracy: 0.9313 - val_loss: 0.1983\n",
      "Epoch 16/30\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 123ms/step - accuracy: 0.9406 - loss: 0.1638 - val_accuracy: 0.9387 - val_loss: 0.1863\n",
      "Epoch 17/30\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 132ms/step - accuracy: 0.9419 - loss: 0.1558 - val_accuracy: 0.9320 - val_loss: 0.2104\n",
      "Epoch 18/30\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 133ms/step - accuracy: 0.9464 - loss: 0.1482 - val_accuracy: 0.9233 - val_loss: 0.2354\n",
      "Epoch 19/30\n",
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 138ms/step - accuracy: 0.9459 - loss: 0.1410 - val_accuracy: 0.9153 - val_loss: 0.2547\n",
      "Test accuracy (upgraded CNN): 0.9290000200271606\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "mask_train = (y_train < 3).flatten()\n",
    "mask_test  = (y_test < 3).flatten()\n",
    "\n",
    "x_train = x_train[mask_train].astype(\"float32\") / 255.0\n",
    "y_train = y_train[mask_train].flatten()\n",
    "x_test  = x_test[mask_test].astype(\"float32\") / 255.0\n",
    "y_test  = y_test[mask_test].flatten()\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=(32,32,3)),\n",
    "\n",
    "    layers.Conv2D(32, 3, padding=\"same\"),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.ReLU(),\n",
    "    layers.Conv2D(32, 3, padding=\"same\"),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.ReLU(),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Dropout(0.25),\n",
    "\n",
    "    layers.Conv2D(64, 3, padding=\"same\"),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.ReLU(),\n",
    "    layers.Conv2D(64, 3, padding=\"same\"),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.ReLU(),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Dropout(0.25),\n",
    "\n",
    "    layers.Conv2D(128, 3, padding=\"same\"),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.ReLU(),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Dropout(0.25),\n",
    "\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation=\"relu\"),\n",
    "    layers.Dropout(0.4),\n",
    "    layers.Dense(3, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "cb = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=3, restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=30,\n",
    "    batch_size=64,\n",
    "    validation_split=0.1,\n",
    "    callbacks=[cb],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "loss, acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Test accuracy (upgraded CNN):\", acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4833ca",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88985dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "mask_train = (y_train < 3).flatten()\n",
    "mask_test  = (y_test < 3).flatten()\n",
    "\n",
    "x_train = x_train[mask_train].astype(\"float32\") / 255.0\n",
    "y_train = y_train[mask_train].flatten()\n",
    "x_test  = x_test[mask_test].astype(\"float32\") / 255.0\n",
    "y_test  = y_test[mask_test].flatten()\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=(32,32,3)),\n",
    "\n",
    "    layers.Conv2D(32, 3, padding=\"same\"),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.ReLU(),\n",
    "    layers.Conv2D(32, 3, padding=\"same\"),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.ReLU(),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Dropout(0.25),\n",
    "\n",
    "    layers.Conv2D(64, 3, padding=\"same\"),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.ReLU(),\n",
    "    layers.Conv2D(64, 3, padding=\"same\"),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.ReLU(),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Dropout(0.25),\n",
    "\n",
    "    layers.Conv2D(128, 3, padding=\"same\"),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.ReLU(),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Dropout(0.25),\n",
    "\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation=\"relu\"),\n",
    "    layers.Dropout(0.4),\n",
    "    layers.Dense(3, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "cb = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=3, restore_best_weights=True\n",
    ")\n",
    "\n",
    "data_aug = tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomTranslation(0.1, 0.1),\n",
    "    layers.RandomZoom(0.1),\n",
    "])\n",
    "\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=30,\n",
    "    batch_size=64,\n",
    "    validation_split=0.1,\n",
    "    callbacks=[cb],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "loss, acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Test accuracy (upgraded CNN):\", acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c57fe2",
   "metadata": {},
   "source": [
    "Transfer Learning (MobileNetV2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b45a591",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "mask_train = (y_train < 3).flatten()\n",
    "mask_test  = (y_test < 3).flatten()\n",
    "\n",
    "x_train = x_train[mask_train].astype(\"float32\")\n",
    "y_train = y_train[mask_train].flatten()\n",
    "x_test  = x_test[mask_test].astype(\"float32\")\n",
    "y_test  = y_test[mask_test].flatten()\n",
    "\n",
    "IMG_SIZE = 96\n",
    "\n",
    "preprocess = tf.keras.Sequential([\n",
    "    layers.Resizing(IMG_SIZE, IMG_SIZE),\n",
    "    layers.Lambda(tf.keras.applications.mobilenet_v2.preprocess_input)\n",
    "])\n",
    "\n",
    "base = tf.keras.applications.MobileNetV2(\n",
    "    input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\"\n",
    ")\n",
    "base.trainable = False\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Input(shape=(32,32,3)),\n",
    "    preprocess,\n",
    "    base,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(3, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "cb = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=2, restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=10,\n",
    "    batch_size=64,\n",
    "    validation_split=0.1,\n",
    "    callbacks=[cb],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "loss, acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Test accuracy (transfer learning):\", acc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
